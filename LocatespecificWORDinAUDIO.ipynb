{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPxNSnYRsIuI",
        "outputId": "a71cc508-4746-4d3d-e490-3d85193cb33b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (0.25.1)\n",
            "Requirement already satisfied: SpeechRecognition in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub SpeechRecognition\n",
        "#yaml file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JbWbnpaZwql",
        "outputId": "eb306fa4-9787-43f5-dffb-a037e9f1e108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: moviepy in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<6.0,>=4.0.2 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from moviepy) (5.1.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from moviepy) (0.1.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from moviepy) (1.24.3)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from moviepy) (2.31.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install moviepy\n",
        "from moviepy.config import change_settings\n",
        "change_settings({\"FFMPEG_BINARY\": \"/usr/bin/ffmpeg\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQrO60nEVdGh",
        "outputId": "44359d22-e08f-4a7a-fac7-05169b183589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.11\n",
            "/Users/gwen/Downloads\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CHbzzmNZZ220"
      },
      "outputs": [],
      "source": [
        "from moviepy.editor import VideoFileClip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dDcF5NCvsJf_"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "\n",
        "audio_file_path = \"./adrd-data/Group2/eyetrack_video_pc0005.wav\"\n",
        "target_word = \"sink\"  # The word you want to search for\n",
        "context_duration_before = 3  # Duration in seconds before the word\n",
        "context_duration_after = 3  # Duration in seconds after the word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "RIKyxubqsf7E"
      },
      "outputs": [],
      "source": [
        "audio = AudioSegment.from_wav(audio_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "EhaCnB6Zsf9X"
      },
      "outputs": [],
      "source": [
        "r = sr.Recognizer()\n",
        "\n",
        "with sr.AudioFile(audio_file_path) as source:\n",
        "    audio_data = r.record(source)\n",
        "    try:\n",
        "        recognized_text = r.recognize_google(audio_data)\n",
        "    except sr.UnknownValueError:\n",
        "        print(\"Speech recognition could not understand audio\")\n",
        "        recognized_text = \"\"\n",
        "    except sr.RequestError as e:\n",
        "        print(f\"Could not request results from Google Speech Recognition service; {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWpv-uyaskyA",
        "outputId": "ba6e1e3e-4474-4242-fa94-4be201a5ba25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start_position:  -1 end_position:  3\n",
            "segment_start_time:  0 segment_end_time:  6\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='output2.wav'>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "start_position = recognized_text.find(target_word)\n",
        "end_position = start_position + len(target_word)\n",
        "\n",
        "print(\"start_position: \", start_position, \"end_position: \", end_position)\n",
        "segment_start_time = max(0, (start_position - context_duration_before))\n",
        "segment_end_time = min(len(audio), (end_position + context_duration_after))\n",
        "\n",
        "print(\"segment_start_time: \", segment_start_time, \"segment_end_time: \", segment_end_time)\n",
        "extracted_segment = audio[segment_start_time * 1000 : segment_end_time * 1000]  # Convert to milliseconds\n",
        "output_path = \"output2.wav\"\n",
        "extracted_segment.export(output_path, format=\"wav\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cNx7leL-GiLO"
      },
      "outputs": [],
      "source": [
        "#start and end for each word in the audio file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1DKStdQLst0K"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydub in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (0.25.1)\n",
            "Requirement already satisfied: SpeechRecognition in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (3.10.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from SpeechRecognition) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (2023.7.22)\n",
            "Requirement already satisfied: pyyaml in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (6.0.1)\n",
            "Requirement already satisfied: gentle in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (0.1)\n",
            "Requirement already satisfied: fabric in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from gentle) (3.2.2)\n",
            "Requirement already satisfied: docopt in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from gentle) (0.6.2)\n",
            "Requirement already satisfied: invoke>=2.0 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from fabric->gentle) (2.2.0)\n",
            "Requirement already satisfied: paramiko>=2.4 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from fabric->gentle) (3.3.1)\n",
            "Requirement already satisfied: decorator>=5 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from fabric->gentle) (5.1.1)\n",
            "Requirement already satisfied: deprecated>=1.2 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from fabric->gentle) (1.2.14)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from deprecated>=1.2->fabric->gentle) (1.15.0)\n",
            "Requirement already satisfied: bcrypt>=3.2 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from paramiko>=2.4->fabric->gentle) (4.0.1)\n",
            "Requirement already satisfied: cryptography>=3.3 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from paramiko>=2.4->fabric->gentle) (41.0.3)\n",
            "Requirement already satisfied: pynacl>=1.5 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from paramiko>=2.4->fabric->gentle) (1.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from cryptography>=3.3->paramiko>=2.4->fabric->gentle) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->gentle) (2.21)\n",
            "Requirement already satisfied: pocketsphinx in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (5.0.2)\n",
            "Requirement already satisfied: sounddevice in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from pocketsphinx) (0.4.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from sounddevice->pocketsphinx) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice->pocketsphinx) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub SpeechRecognition\n",
        "!pip install pyyaml\n",
        "!pip install gentle\n",
        "!pip install pocketsphinx "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "iXwUWkwGnfEe",
        "outputId": "d0eab9cd-c2f0-46fc-ddc4-430c5c34ec6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'transcript': \"okay so we can check with you instead okay and why is it wrong to me don't force it doesn't picture the wife was washing dishes outside from the cookie jar and the boys are you outside the house there's a tree the curtains a little girl was reaching out cookie all right so now we're done with the address and we will so for the second part\", 'confidence': 0.14436238}\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'timestamps'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m alternative \u001b[39min\u001b[39;00m recognizer\u001b[39m.\u001b[39mrecognize_google(audio, show_all\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m'\u001b[39m\u001b[39malternative\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(alternative)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     timestamps\u001b[39m.\u001b[39mextend(alternative[\u001b[39m'\u001b[39;49m\u001b[39mtimestamps\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Print the word, start time, and end time for each word\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m word_info \u001b[39min\u001b[39;00m timestamps:\n",
            "\u001b[0;31mKeyError\u001b[0m: 'timestamps'"
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "import gentle\n",
        "import yaml\n",
        "from pocketsphinx import AudioFile\n",
        "\n",
        "# Load the WAV file\n",
        "audio_file_path = \"./adrd-data/Group2/eyetrack_video_pc0005.wav\"\n",
        "\n",
        "# Initialize the recognizer\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Load the audio file using SpeechRecognition\n",
        "with sr.AudioFile(audio_file_path) as source:\n",
        "    audio = recognizer.record(source)  # Record the entire audio\n",
        "\n",
        "# Perform speech recognition and get the timestamps of words\n",
        "timestamps = []\n",
        "for alternative in recognizer.recognize_google(audio, show_all=True)['alternative']:\n",
        "    print(alternative)\n",
        "    timestamps.extend(alternative['timestamps'])\n",
        "\n",
        "# Print the word, start time, and end time for each word\n",
        "for word_info in timestamps:\n",
        "    word = word_info[0]\n",
        "    start_time = word_info[1]\n",
        "    end_time = word_info[2]\n",
        "    print(f\"Word: {word}, Start Time: {start_time}, End Time: {end_time}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw45QHeXr0tC",
        "outputId": "6531f80a-149d-4965-91f7-485abb056309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pocketsphinx in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (5.0.2)\n",
            "Requirement already satisfied: sounddevice in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from pocketsphinx) (0.4.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from sounddevice->pocketsphinx) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice->pocketsphinx) (2.21)\n",
            "Requirement already satisfied: gentle in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (0.1)\n",
            "Requirement already satisfied: fabric in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from gentle) (3.2.2)\n",
            "Requirement already satisfied: docopt in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from gentle) (0.6.2)\n",
            "Requirement already satisfied: invoke>=2.0 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from fabric->gentle) (2.2.0)\n",
            "Requirement already satisfied: paramiko>=2.4 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from fabric->gentle) (3.3.1)\n",
            "Requirement already satisfied: decorator>=5 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from fabric->gentle) (5.1.1)\n",
            "Requirement already satisfied: deprecated>=1.2 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from fabric->gentle) (1.2.14)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from deprecated>=1.2->fabric->gentle) (1.15.0)\n",
            "Requirement already satisfied: bcrypt>=3.2 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from paramiko>=2.4->fabric->gentle) (4.0.1)\n",
            "Requirement already satisfied: cryptography>=3.3 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from paramiko>=2.4->fabric->gentle) (41.0.3)\n",
            "Requirement already satisfied: pynacl>=1.5 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from paramiko>=2.4->fabric->gentle) (1.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from cryptography>=3.3->paramiko>=2.4->fabric->gentle) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->gentle) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install pocketsphinx\n",
        "!pip install gentle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "919AmPgYot9k",
        "outputId": "36883acb-a471-4195-b709-3291bbf5d6ed"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'gentle' has no attribute 'resample'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m transcript \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39ma woman is drawing a Dish as she stands by the kitchen sink the kitchen sink is overflowing with a lot of water onto the ground the woman is also stepping into the puddle of water the woman is looking out the window where you can see the house is Back Garden and to the left of the woman that are two children the little girl is laughing at the little boy the Boy seems to be falling off a stool as he reaches for a jar of cookies the girl is on the floor and she\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms laughing at the guy and the woman seems to be unbothered by the fact that the little boys falling off the stool she is just look out the window\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Create a language model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m resources \u001b[39m=\u001b[39m gentle\u001b[39m.\u001b[39;49mresample()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Transcribe and align the audio\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m aligner \u001b[39m=\u001b[39m gentle\u001b[39m.\u001b[39mForcedAligner(resources, transcript)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'gentle' has no attribute 'resample'"
          ]
        }
      ],
      "source": [
        "import gentle\n",
        "\n",
        "# Load the WAV audio file\n",
        "audio_file_path = \"./adrd-data/Group2/eyetrack_video_pc0005.wav\"\n",
        "\n",
        "\n",
        "# Provide a reference transcript\n",
        "transcript = \"a woman is drawing a Dish as she stands by the kitchen sink the kitchen sink is overflowing with a lot of water onto the ground the woman is also stepping into the puddle of water the woman is looking out the window where you can see the house is Back Garden and to the left of the woman that are two children the little girl is laughing at the little boy the Boy seems to be falling off a stool as he reaches for a jar of cookies the girl is on the floor and she's laughing at the guy and the woman seems to be unbothered by the fact that the little boys falling off the stool she is just look out the window\"\n",
        "\n",
        "# Create a language model\n",
        "resources = gentle.resample()\n",
        "\n",
        "# Transcribe and align the audio\n",
        "aligner = gentle.ForcedAligner(resources, transcript)\n",
        "aligner.transcribe(audio_file_path)\n",
        "\n",
        "# Print word-level timestamps\n",
        "for word in aligner.transcript.words:\n",
        "    print(f\"Word: {word.word}, Start Time: {word.start}, End Time: {word.end}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx9CaqDRvReR",
        "outputId": "260ddbbb-6f38-4b41-cb60-8dc7c0d5e73b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of audio_segment=360.896 seconds\n",
            "start,Stop\n",
            "[3.022, 3.394]\n",
            "[11.886, 12.246]\n",
            "[15.569, 15.793]\n",
            "[33.411, 33.938]\n",
            "[34.493, 34.552]\n",
            "[36.845, 37.371]\n",
            "[40.768, 42.343]\n",
            "[43.192, 44.303]\n",
            "[49.653, 49.852]\n",
            "[65.693, 65.888]\n",
            "[66.675, 66.85]\n",
            "[98.21, 98.771]\n",
            "[99.808, 100.492]\n",
            "[102.3, 102.472]\n",
            "[107.471, 107.639]\n",
            "[108.817, 109.505]\n",
            "[115.51, 115.516]\n",
            "[149.286, 151.154]\n",
            "[153.909, 154.04]\n",
            "[163.537, 163.616]\n",
            "[199.251, 199.314]\n",
            "[201.402, 202.35]\n",
            "[212.426, 212.443]\n",
            "[217.129, 217.161]\n",
            "[245.494, 245.495]\n",
            "[249.683, 249.778]\n",
            "[251.158, 251.317]\n",
            "[270.764, 271.131]\n",
            "[273.985, 274.128]\n",
            "[275.615, 276.368]\n",
            "[277.177, 277.42]\n",
            "[279.676, 279.699]\n",
            "[287.597, 287.914]\n",
            "[290.031, 290.062]\n",
            "[303.093, 303.196]\n",
            "[327.457, 327.945]\n",
            "[328.815, 328.834]\n",
            "[329.552, 329.588]\n",
            "[330.475, 332.131]\n",
            "[332.743, 333.136]\n",
            "[336.406, 336.883]\n",
            "[338.616, 338.659]\n",
            "[342.21, 345.08]\n",
            "[347.465, 349.022]\n",
            "[349.68, 350.059]\n",
            "[350.574, 350.833]\n"
          ]
        }
      ],
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.silence import detect_nonsilent\n",
        "\n",
        "#adjust target amplitude\n",
        "def match_target_amplitude(sound, target_dBFS):\n",
        "    change_in_dBFS = target_dBFS - sound.dBFS\n",
        "    return sound.apply_gain(change_in_dBFS)\n",
        "\n",
        "#Convert wav to audio_segment\n",
        "audio_segment = AudioSegment.from_wav(\"./adrd-data/Group2/eyetrack_video_pc0005.wav\")\n",
        "\n",
        "#normalize audio_segment to -20dBFS\n",
        "normalized_sound = match_target_amplitude(audio_segment, -20.0)\n",
        "print(\"length of audio_segment={} seconds\".format(len(normalized_sound)/1000))\n",
        "\n",
        "#Print detected non-silent chunks, which in our case would be spoken words.\n",
        "nonsilent_data = detect_nonsilent(normalized_sound, min_silence_len=500, silence_thresh=-20, seek_step=1)\n",
        "\n",
        "#convert ms to seconds\n",
        "print(\"start,Stop\")\n",
        "for chunks in nonsilent_data:\n",
        "    print( [chunk/1000 for chunk in chunks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RhRmYjyy5q7",
        "outputId": "9b9a74e3-f1d7-4e7f-edf5-b0b206f9091a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SimpleAudioIndexer in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (1.0.0)\n",
            "Requirement already satisfied: requests in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from SimpleAudioIndexer) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests->SimpleAudioIndexer) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests->SimpleAudioIndexer) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests->SimpleAudioIndexer) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests->SimpleAudioIndexer) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install SimpleAudioIndexer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "FT8-edSWxoXY"
      },
      "outputs": [
        {
          "ename": "ConnectionError",
          "evalue": "HTTPSConnectionPool(host='stream.watsonplatform.net', port=443): Max retries exceeded with url: /speech-to-text/api/v1/recognize?continuous=True&model=en-US_BroadbandModel&word_alternatives_threshold=0.9&word_confidence=True&timestamps=True&inactivity_timeout=-1&profanity_filter=False (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x11f31a9e0>: Failed to resolve 'stream.watsonplatform.net' ([Errno 8] nodename nor servname provided, or not known)\"))",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/urllib3/connection.py:200\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     sock \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    201\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport),\n\u001b[1;32m    202\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m    203\u001b[0m         source_address\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msource_address,\n\u001b[1;32m    204\u001b[0m         socket_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket_options,\n\u001b[1;32m    205\u001b[0m     )\n\u001b[1;32m    206\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/urllib3/util/connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39mraise\u001b[39;00m LocationParseError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mhost\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, label empty or too long\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, socket\u001b[39m.\u001b[39;49mSOCK_STREAM):\n\u001b[1;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/socket.py:955\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    954\u001b[0m addrlist \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 955\u001b[0m \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m _socket\u001b[39m.\u001b[39;49mgetaddrinfo(host, port, family, \u001b[39mtype\u001b[39;49m, proto, flags):\n\u001b[1;32m    956\u001b[0m     af, socktype, proto, canonname, sa \u001b[39m=\u001b[39m res\n",
            "\u001b[0;31mgaierror\u001b[0m: [Errno 8] nodename nor servname provided, or not known",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mNameResolutionError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/urllib3/connectionpool.py:491\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    490\u001b[0m         new_e \u001b[39m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[39m.\u001b[39mproxy\u001b[39m.\u001b[39mscheme)\n\u001b[0;32m--> 491\u001b[0m     \u001b[39mraise\u001b[39;00m new_e\n\u001b[1;32m    493\u001b[0m \u001b[39m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 467\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    468\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/urllib3/connectionpool.py:1092\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m conn\u001b[39m.\u001b[39mis_closed:\n\u001b[0;32m-> 1092\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1094\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/urllib3/connection.py:604\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    603\u001b[0m sock: socket\u001b[39m.\u001b[39msocket \u001b[39m|\u001b[39m ssl\u001b[39m.\u001b[39mSSLSocket\n\u001b[0;32m--> 604\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m sock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    605\u001b[0m server_hostname: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/urllib3/connection.py:207\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39mgaierror \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mraise\u001b[39;00m NameResolutionError(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m, e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout \u001b[39mas\u001b[39;00m e:\n",
            "\u001b[0;31mNameResolutionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x11f31a9e0>: Failed to resolve 'stream.watsonplatform.net' ([Errno 8] nodename nor servname provided, or not known)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/urllib3/connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    842\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[0;32m--> 844\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    845\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/urllib3/util/retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    514\u001b[0m     reason \u001b[39m=\u001b[39m error \u001b[39mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 515\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[39mfrom\u001b[39;00m \u001b[39mreason\u001b[39;00m  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    517\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='stream.watsonplatform.net', port=443): Max retries exceeded with url: /speech-to-text/api/v1/recognize?continuous=True&model=en-US_BroadbandModel&word_alternatives_threshold=0.9&word_confidence=True&timestamps=True&inactivity_timeout=-1&profanity_filter=False (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x11f31a9e0>: Failed to resolve 'stream.watsonplatform.net' ([Errno 8] nodename nor servname provided, or not known)\"))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[1;32m/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb Cell 16\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mSimpleAudioIndexer\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleAudioIndexer \u001b[39mas\u001b[39;00m sai\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m indexer \u001b[39m=\u001b[39m sai(mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mibm\u001b[39m\u001b[39m\"\u001b[39m, src_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./adrd-data/Group2/\u001b[39m\u001b[39m\"\u001b[39m, username_ibm\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, password_ibm\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m indexer\u001b[39m.\u001b[39;49mindex_audio(basename \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39meyetrack_video_pc0005.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m indexer\u001b[39m.\u001b[39msave_indexed_audio(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/indexed_audio\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(indexer\u001b[39m.\u001b[39msrc_dir))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gwen/Downloads/LocatespecificWORDinAUDIO.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m indexer\u001b[39m.\u001b[39mload_indexed_audio(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/indexed_audio.txt\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(indexer\u001b[39m.\u001b[39msrc_dir))\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/SimpleAudioIndexer/__init__.py:1108\u001b[0m, in \u001b[0;36mSimpleAudioIndexer.index_audio\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[39mwith\u001b[39;00m _Subdirectory_Managing_Decorator(\n\u001b[1;32m   1106\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needed_directories):\n\u001b[1;32m   1107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_mode() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mibm\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 1108\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_index_audio_ibm(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1109\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_mode() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcmu\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1110\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_audio_cmu(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/SimpleAudioIndexer/__init__.py:938\u001b[0m, in \u001b[0;36mSimpleAudioIndexer._index_audio_ibm\u001b[0;34m(self, basename, replace_already_indexed, continuous, model, word_confidence, word_alternatives_threshold, profanity_filter_for_US_results)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_verbosity():\n\u001b[1;32m    937\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mUploading \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(staging_audio_basename))\n\u001b[0;32m--> 938\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mpost(\n\u001b[1;32m    939\u001b[0m     url\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://stream.watsonplatform.net/\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    940\u001b[0m          \u001b[39m\"\u001b[39;49m\u001b[39mspeech-to-text/api/v1/recognize\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    941\u001b[0m     auth\u001b[39m=\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_username_ibm(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_password_ibm()),\n\u001b[1;32m    942\u001b[0m     headers\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mcontent-type\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39maudio/wav\u001b[39;49m\u001b[39m'\u001b[39;49m},\n\u001b[1;32m    943\u001b[0m     data\u001b[39m=\u001b[39;49mf\u001b[39m.\u001b[39;49mread(),\n\u001b[1;32m    944\u001b[0m     params\u001b[39m=\u001b[39;49mparams)\n\u001b[1;32m    945\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_verbosity():\n\u001b[1;32m    946\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIndexing \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(staging_audio_basename))\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(url, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, data\u001b[39m=\u001b[39;49mdata, json\u001b[39m=\u001b[39;49mjson, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
            "File \u001b[0;32m~/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages/requests/adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    516\u001b[0m         \u001b[39m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[39mraise\u001b[39;00m SSLError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m--> 519\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    521\u001b[0m \u001b[39mexcept\u001b[39;00m ClosedPoolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    522\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(e, request\u001b[39m=\u001b[39mrequest)\n",
            "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='stream.watsonplatform.net', port=443): Max retries exceeded with url: /speech-to-text/api/v1/recognize?continuous=True&model=en-US_BroadbandModel&word_alternatives_threshold=0.9&word_confidence=True&timestamps=True&inactivity_timeout=-1&profanity_filter=False (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x11f31a9e0>: Failed to resolve 'stream.watsonplatform.net' ([Errno 8] nodename nor servname provided, or not known)\"))"
          ]
        }
      ],
      "source": [
        "from SimpleAudioIndexer import SimpleAudioIndexer as sai\n",
        "indexer = sai(mode=\"ibm\", src_dir=\"./adrd-data/Group2/\", username_ibm=\"\", password_ibm=\"\")\n",
        "indexer.index_audio(basename = \"eyetrack_video_pc0005.wav\")\n",
        "indexer.save_indexed_audio(\"{}/indexed_audio\".format(indexer.src_dir))\n",
        "indexer.load_indexed_audio(\"{}/indexed_audio.txt\".format(indexer.src_dir))\n",
        "print(indexer.get_timestamps())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GM8y-1c2c96",
        "outputId": "671f1431-4748-4dd5-ae70-65f5e46ad7f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vosk in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (0.3.44)\n",
            "Requirement already satisfied: cffi>=1.0 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from vosk) (1.15.1)\n",
            "Requirement already satisfied: requests in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from vosk) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from vosk) (4.65.0)\n",
            "Requirement already satisfied: srt in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from vosk) (3.5.3)\n",
            "Requirement already satisfied: websockets in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from vosk) (11.0.3)\n",
            "Requirement already satisfied: pycparser in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from cffi>=1.0->vosk) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests->vosk) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests->vosk) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests->vosk) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/gwen/anaconda3/envs/adrd_scripts/lib/python3.10/site-packages (from requests->vosk) (2023.7.22)\n",
            "Running `brew update --auto-update`...\n",
            "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
            "Updated 3 taps (homebrew/cask-fonts, homebrew/core and homebrew/cask).\n",
            "\u001b[34m==>\u001b[0m \u001b[1mNew Formulae\u001b[0m\n",
            "bandicoot                  incus                      pter\n",
            "bashunit                   iocextract                 python-argcomplete\n",
            "biome                      jupyter-r                  python-gdbm@3.12\n",
            "blake3                     karmadactl                 python-psutil\n",
            "bozohttpd                  ldeep                      python-setuptools\n",
            "build2                     libdicom                   python-tk@3.12\n",
            "caracal                    libimobiledevice-glue      python@3.12\n",
            "cf2tf                      libmapper                  qalculate-qt\n",
            "chainloop-cli              libnghttp3                 saf-cli\n",
            "cloudsplaining             llvm@16                    scoutsuite\n",
            "colmap                     mentat                     smlfmt\n",
            "dcp                        modsecurity                sqlsmith\n",
            "dezoomify-rs               mtbl                       squiid\n",
            "diffoci                    netlistsvg                 tailwindcss\n",
            "dockly                     numbat                     trafilatura\n",
            "dovi_tool                  nvimpager                  uffizzi\n",
            "ggshield                   onionprobe                 web-ext\n",
            "ghc@9.4                    opentofu                   wormhole-william\n",
            "gossip                     orcania                    yder\n",
            "gptline                    orogene\n",
            "helidon                    postgresql@16\n",
            "\u001b[34m==>\u001b[0m \u001b[1mNew Casks\u001b[0m\n",
            "akuity                                   free-podcast-transcription\n",
            "ava                                      hp-easy-admin\n",
            "batteryboi                               kuaitie\n",
            "chainner                                 low-profile\n",
            "clinq                                    meld-studio\n",
            "cloudnet                                 modrinth\n",
            "devtunnel                                mutedeck\n",
            "dropbox-dash                             muyu\n",
            "dropshelf                                paulxstretch\n",
            "ecodms-client                            playdate-mirror\n",
            "expo-orbit                               reqable\n",
            "finbar                                   routine\n",
            "font-agbalumo                            rustrover\n",
            "font-fzfangsong-z02                      sf\n",
            "font-fzkai-z03                           songkong\n",
            "font-fzxiaobiaosong-b05                  space-capsule\n",
            "font-gabarito                            spacedrive\n",
            "font-kay-pho-du                          spundle\n",
            "font-linefont                            telegram-a\n",
            "font-noto-sans-kawi                      to-audio-converter\n",
            "font-noto-serif-old-uyghur               twelite-stage\n",
            "font-pixelify-sans                       wetype\n",
            "font-reddit-sans\n",
            "\n",
            "You have \u001b[1m6\u001b[0m outdated formulae installed.\n",
            "\n",
            "\u001b[33mWarning:\u001b[0m wget 1.21.4 is already installed and up-to-date.\n",
            "To reinstall 1.21.4, run:\n",
            "  brew reinstall wget\n"
          ]
        }
      ],
      "source": [
        "!pip install vosk\n",
        "!brew install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_04CGqRA2u_x"
      },
      "outputs": [],
      "source": [
        "!touch Word.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "zibwQDiF2RTc"
      },
      "outputs": [],
      "source": [
        "class Word:\n",
        "    ''' A class representing a word from the JSON format for vosk speech recognition API '''\n",
        "\n",
        "    def __init__(self, dict):\n",
        "        '''\n",
        "        Parameters:\n",
        "          dict (dict) dictionary from JSON, containing:\n",
        "            conf (float): degree of confidence, from 0 to 1\n",
        "            end (float): end time of the pronouncing the word, in seconds\n",
        "            start (float): start time of the pronouncing the word, in seconds\n",
        "            word (str): recognized word\n",
        "        '''\n",
        "\n",
        "        self.conf = dict[\"conf\"]\n",
        "        self.end = dict[\"end\"]\n",
        "        self.start = dict[\"start\"]\n",
        "        self.word = dict[\"word\"]\n",
        "\n",
        "    def to_string(self):\n",
        "        ''' Returns a string describing this instance '''\n",
        "        return \"{:20} from {:.2f} sec to {:.2f} sec, confidence is {:.2f}%\".format(\n",
        "            self.word, self.start, self.end, self.conf*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XitpGc3u3TKx",
        "outputId": "9ca69994-a0aa-428e-e628-0c53c2ca82de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-16 17:36:32--  https://alphacephei.com/vosk/models/vosk-model-en-us-0.21.zip\n",
            "Resolving alphacephei.com (alphacephei.com)... 188.40.21.16\n",
            "Connecting to alphacephei.com (alphacephei.com)|188.40.21.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1752830350 (1.6G) [application/zip]\n",
            "Saving to: vosk-model-en-us-0.21.zip\n",
            "\n",
            "del-en-us-0.21.zip    3%[                    ]  56.66M  3.00MB/s    eta 7m 33s ^C\n"
          ]
        }
      ],
      "source": [
        "!wget https://alphacephei.com/vosk/models/vosk-model-en-us-0.21.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD6r8Z3T36jL",
        "outputId": "d2efd223-d937-42fa-bc4e-baa07f3197ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  ./vosk-model-en-us-0.21.zip\n",
            "replace vosk-model-en-us-0.21/am/final.mdl? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
          ]
        }
      ],
      "source": [
        "!unzip ./vosk-model-en-us-0.21.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "7UwwLS0P4Ayd"
      },
      "outputs": [],
      "source": [
        "!mkdir models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Bq_zKlLc0RT2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
            "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 1 orphan nodes.\n",
            "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 2 orphan components.\n",
            "LOG (VoskAPI:Collapse():nnet-utils.cc:1488) Added 1 components, removed 2\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from models/vosk-model-en-us-0.21/ivector/final.ie\n",
            "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
            "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from models/vosk-model-en-us-0.21/graph/HCLG.fst\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:294) Loading words from models/vosk-model-en-us-0.21/graph/words.txt\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo models/vosk-model-en-us-0.21/graph/phones/word_boundary.int\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading subtract G.fst model from models/vosk-model-en-us-0.21/rescore/G.fst\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:312) Loading CARPA model from models/vosk-model-en-us-0.21/rescore/G.carpa\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:318) Loading RNNLM model from models/vosk-model-en-us-0.21/rnnlm/final.raw\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sure                 from 3.00 sec to 3.66 sec, confidence is 100.00%\n",
            "and                  from 5.49 sec to 6.11 sec, confidence is 82.48%\n",
            "the                  from 6.11 sec to 6.39 sec, confidence is 100.00%\n",
            "numbers              from 6.51 sec to 7.80 sec, confidence is 100.00%\n",
            "show                 from 7.98 sec to 8.70 sec, confidence is 100.00%\n",
            "no                   from 9.45 sec to 10.08 sec, confidence is 94.97%\n",
            "it's                 from 11.61 sec to 12.00 sec, confidence is 52.94%\n",
            "true                 from 12.00 sec to 12.78 sec, confidence is 91.86%\n",
            "hmm                  from 16.32 sec to 20.07 sec, confidence is 69.79%\n",
            "all                  from 22.80 sec to 23.19 sec, confidence is 40.38%\n",
            "seems                from 23.19 sec to 23.97 sec, confidence is 40.38%\n",
            "wrong                from 24.00 sec to 24.81 sec, confidence is 52.19%\n",
            "summer               from 26.61 sec to 27.42 sec, confidence is 50.80%\n",
            "going                from 29.73 sec to 30.00 sec, confidence is 98.39%\n",
            "through              from 30.00 sec to 30.36 sec, confidence is 98.39%\n",
            "a                    from 30.60 sec to 30.75 sec, confidence is 98.39%\n",
            "few                  from 30.75 sec to 31.23 sec, confidence is 98.39%\n",
            "rounds               from 31.29 sec to 32.16 sec, confidence is 83.24%\n",
            "mama                 from 33.78 sec to 34.53 sec, confidence is 62.94%\n",
            "show                 from 42.96 sec to 43.50 sec, confidence is 100.00%\n",
            "me                   from 43.56 sec to 44.19 sec, confidence is 100.00%\n",
            "the                  from 55.14 sec to 55.56 sec, confidence is 100.00%\n",
            "fashion              from 55.89 sec to 56.64 sec, confidence is 100.00%\n",
            "show                 from 56.64 sec to 57.30 sec, confidence is 100.00%\n",
            "ooh                  from 58.32 sec to 58.62 sec, confidence is 30.23%\n",
            "come                 from 66.51 sec to 67.11 sec, confidence is 38.12%\n",
            "on                   from 67.13 sec to 67.98 sec, confidence is 88.46%\n",
            "lunch                from 67.98 sec to 68.70 sec, confidence is 100.00%\n",
            "and                  from 69.84 sec to 70.23 sec, confidence is 100.00%\n",
            "moshe                from 70.47 sec to 71.16 sec, confidence is 100.00%\n",
            "i                    from 73.50 sec to 74.22 sec, confidence is 73.77%\n",
            "got                  from 74.22 sec to 74.58 sec, confidence is 28.26%\n",
            "her                  from 74.59 sec to 75.27 sec, confidence is 96.44%\n",
            "ghost                from 84.75 sec to 85.44 sec, confidence is 93.07%\n",
            "brooklyn             from 88.53 sec to 89.01 sec, confidence is 42.84%\n",
            "hey                  from 99.24 sec to 99.54 sec, confidence is 53.59%\n",
            "abortion             from 107.82 sec to 109.26 sec, confidence is 24.21%\n",
            "during               from 111.24 sec to 111.75 sec, confidence is 100.00%\n",
            "the                  from 111.75 sec to 112.71 sec, confidence is 100.00%\n",
            "war                  from 112.74 sec to 113.25 sec, confidence is 88.79%\n",
            "oh                   from 117.00 sec to 117.33 sec, confidence is 100.00%\n",
            "what's               from 118.56 sec to 120.27 sec, confidence is 67.76%\n",
            "on                   from 120.72 sec to 121.35 sec, confidence is 67.76%\n",
            "a                    from 121.44 sec to 121.74 sec, confidence is 67.76%\n",
            "woman's              from 121.74 sec to 122.52 sec, confidence is 67.76%\n",
            "warmth               from 122.52 sec to 123.33 sec, confidence is 56.83%\n",
            "harper               from 133.56 sec to 134.16 sec, confidence is 21.00%\n",
            "hi                   from 139.20 sec to 159.36 sec, confidence is 39.92%\n",
            "whoosh               from 159.36 sec to 165.38 sec, confidence is 66.49%\n",
            "zero                 from 174.63 sec to 175.62 sec, confidence is 31.31%\n",
            "kurt                 from 179.39 sec to 180.15 sec, confidence is 92.73%\n",
            "warner               from 180.15 sec to 180.78 sec, confidence is 92.73%\n",
            "need                 from 180.78 sec to 181.14 sec, confidence is 97.29%\n",
            "to                   from 181.17 sec to 181.44 sec, confidence is 97.29%\n",
            "know                 from 181.44 sec to 181.93 sec, confidence is 97.29%\n",
            "when                 from 182.01 sec to 182.22 sec, confidence is 73.27%\n",
            "to                   from 182.22 sec to 182.40 sec, confidence is 81.27%\n",
            "want                 from 182.40 sec to 182.91 sec, confidence is 100.00%\n",
            "to                   from 182.91 sec to 183.24 sec, confidence is 100.00%\n",
            "go                   from 183.87 sec to 184.89 sec, confidence is 85.04%\n",
            "throw                from 186.45 sec to 187.65 sec, confidence is 61.86%\n",
            "shirt                from 187.71 sec to 188.28 sec, confidence is 28.99%\n",
            "hush                 from 192.44 sec to 192.96 sec, confidence is 40.90%\n",
            "the                  from 194.04 sec to 194.23 sec, confidence is 22.80%\n",
            "hair                 from 194.23 sec to 194.94 sec, confidence is 73.75%\n",
            "had                  from 197.79 sec to 198.39 sec, confidence is 88.87%\n",
            "no                   from 198.90 sec to 199.44 sec, confidence is 87.61%\n",
            "birds                from 199.47 sec to 200.46 sec, confidence is 79.48%\n",
            "from                 from 200.46 sec to 200.82 sec, confidence is 89.25%\n",
            "those                from 201.57 sec to 201.96 sec, confidence is 100.00%\n",
            "sharpens             from 201.96 sec to 203.16 sec, confidence is 63.46%\n",
            "to                   from 203.16 sec to 203.31 sec, confidence is 100.00%\n",
            "it's                 from 203.31 sec to 203.73 sec, confidence is 56.87%\n",
            "destination          from 203.76 sec to 204.76 sec, confidence is 100.00%\n",
            "i                    from 204.76 sec to 205.05 sec, confidence is 77.72%\n",
            "want                 from 205.11 sec to 205.47 sec, confidence is 90.25%\n",
            "to                   from 205.47 sec to 205.80 sec, confidence is 86.98%\n",
            "get                  from 205.83 sec to 206.16 sec, confidence is 48.41%\n",
            "to                   from 206.16 sec to 206.34 sec, confidence is 48.65%\n",
            "know                 from 206.34 sec to 206.88 sec, confidence is 48.22%\n",
            "smith                from 207.08 sec to 208.08 sec, confidence is 100.00%\n",
            "to                   from 208.11 sec to 208.62 sec, confidence is 100.00%\n",
            "move                 from 208.62 sec to 209.19 sec, confidence is 100.00%\n",
            "can                  from 209.22 sec to 210.15 sec, confidence is 74.96%\n",
            "i've                 from 213.42 sec to 213.81 sec, confidence is 100.00%\n",
            "had                  from 213.81 sec to 214.23 sec, confidence is 100.00%\n",
            "lol                  from 215.28 sec to 215.76 sec, confidence is 29.16%\n",
            "change               from 229.20 sec to 229.89 sec, confidence is 37.62%\n",
            "the                  from 230.28 sec to 230.61 sec, confidence is 72.82%\n",
            "torsion              from 231.30 sec to 232.14 sec, confidence is 80.33%\n",
            "sharing              from 233.79 sec to 234.57 sec, confidence is 100.00%\n",
            "a                    from 234.60 sec to 234.74 sec, confidence is 83.12%\n",
            "bad                  from 234.74 sec to 235.14 sec, confidence is 48.42%\n",
            "one                  from 235.14 sec to 235.74 sec, confidence is 59.70%\n",
            "costs                from 248.58 sec to 249.18 sec, confidence is 72.58%\n",
            "more                 from 249.24 sec to 249.99 sec, confidence is 100.00%\n",
            "than                 from 250.07 sec to 250.35 sec, confidence is 55.16%\n",
            "that                 from 250.38 sec to 250.89 sec, confidence is 51.79%\n",
            "once                 from 255.18 sec to 255.84 sec, confidence is 100.00%\n",
            "more                 from 255.93 sec to 256.83 sec, confidence is 100.00%\n",
            "warming              from 257.46 sec to 258.33 sec, confidence is 47.56%\n",
            "hmm                  from 259.44 sec to 264.03 sec, confidence is 69.79%\n",
            "sure                 from 274.74 sec to 275.55 sec, confidence is 35.50%\n",
            "most                 from 275.79 sec to 276.33 sec, confidence is 100.00%\n",
            "roofs                from 276.33 sec to 277.05 sec, confidence is 100.00%\n",
            "dash                 from 281.04 sec to 281.55 sec, confidence is 41.32%\n",
            "motion               from 281.58 sec to 282.12 sec, confidence is 87.09%\n",
            "she                  from 282.12 sec to 282.45 sec, confidence is 92.13%\n",
            "can                  from 282.48 sec to 282.78 sec, confidence is 100.00%\n",
            "do                   from 282.78 sec to 283.05 sec, confidence is 85.70%\n",
            "this                 from 283.08 sec to 283.53 sec, confidence is 85.70%\n",
            "no                   from 285.90 sec to 286.32 sec, confidence is 48.84%\n",
            "have                 from 290.46 sec to 290.68 sec, confidence is 22.80%\n",
            "the                  from 290.68 sec to 291.51 sec, confidence is 97.94%\n",
            "switch               from 291.96 sec to 292.56 sec, confidence is 90.24%\n",
            "version              from 292.59 sec to 293.10 sec, confidence is 90.24%\n",
            "reception            from 293.10 sec to 293.91 sec, confidence is 29.65%\n",
            "can                  from 295.50 sec to 295.89 sec, confidence is 60.93%\n",
            "you                  from 295.90 sec to 296.58 sec, confidence is 83.38%\n",
            "oh                   from 304.23 sec to 305.25 sec, confidence is 100.00%\n",
            "ethel                from 305.46 sec to 306.30 sec, confidence is 63.38%\n",
            "nose                 from 306.48 sec to 307.17 sec, confidence is 45.28%\n",
            "too                  from 307.23 sec to 307.86 sec, confidence is 91.58%\n",
            "long                 from 307.89 sec to 308.70 sec, confidence is 95.12%\n",
            "i'm                  from 310.65 sec to 311.07 sec, confidence is 75.44%\n",
            "on                   from 311.07 sec to 311.49 sec, confidence is 75.44%\n",
            "call                 from 311.58 sec to 312.57 sec, confidence is 92.52%\n",
            "i'm                  from 315.00 sec to 316.02 sec, confidence is 87.11%\n",
            "jewish               from 316.05 sec to 317.01 sec, confidence is 92.80%\n",
            "shine                from 318.81 sec to 319.77 sec, confidence is 39.50%\n",
            "hush                 from 320.88 sec to 321.30 sec, confidence is 53.44%\n",
            "hush                 from 322.77 sec to 323.61 sec, confidence is 71.37%\n",
            "lotion               from 325.08 sec to 325.95 sec, confidence is 41.39%\n",
            "hope                 from 327.60 sec to 328.44 sec, confidence is 97.11%\n",
            "to                   from 328.44 sec to 328.68 sec, confidence is 97.11%\n",
            "see                  from 328.68 sec to 329.16 sec, confidence is 97.11%\n",
            "more                 from 329.25 sec to 329.70 sec, confidence is 97.11%\n",
            "wall                 from 329.70 sec to 330.12 sec, confidence is 47.54%\n",
            "one                  from 351.43 sec to 351.87 sec, confidence is 78.99%\n",
            "new                  from 355.86 sec to 356.47 sec, confidence is 83.19%\n",
            "nest                 from 356.47 sec to 357.27 sec, confidence is 27.61%\n",
            "no                   from 358.50 sec to 359.46 sec, confidence is 100.00%\n",
            "i                    from 370.05 sec to 370.20 sec, confidence is 55.18%\n",
            "don't                from 370.20 sec to 370.44 sec, confidence is 59.27%\n",
            "know                 from 370.44 sec to 370.65 sec, confidence is 59.27%\n",
            "warrants             from 370.65 sec to 371.34 sec, confidence is 38.77%\n",
            "watched              from 372.48 sec to 373.12 sec, confidence is 69.98%\n",
            "use                  from 376.50 sec to 376.83 sec, confidence is 96.99%\n",
            "it                   from 376.83 sec to 376.92 sec, confidence is 96.99%\n",
            "for                  from 376.92 sec to 377.25 sec, confidence is 96.99%\n",
            "a                    from 377.25 sec to 377.34 sec, confidence is 96.99%\n",
            "long                 from 377.34 sec to 377.97 sec, confidence is 96.99%\n",
            "time                 from 378.00 sec to 378.54 sec, confidence is 96.99%\n",
            "in                   from 378.57 sec to 379.06 sec, confidence is 100.00%\n",
            "them                 from 379.06 sec to 379.56 sec, confidence is 38.35%\n",
            "no                   from 382.41 sec to 383.31 sec, confidence is 47.62%\n",
            "need                 from 383.73 sec to 384.06 sec, confidence is 83.32%\n",
            "to                   from 384.06 sec to 384.24 sec, confidence is 86.08%\n",
            "say                  from 384.24 sec to 384.66 sec, confidence is 98.59%\n",
            "any                  from 384.72 sec to 385.11 sec, confidence is 51.85%\n",
            "more                 from 385.14 sec to 385.56 sec, confidence is 51.85%\n",
            "oh                   from 398.25 sec to 399.03 sec, confidence is 100.00%\n",
            "for                  from 400.08 sec to 400.48 sec, confidence is 50.55%\n",
            "the                  from 400.48 sec to 401.91 sec, confidence is 56.15%\n",
            "however              from 402.96 sec to 404.97 sec, confidence is 61.62%\n",
            "no                   from 408.84 sec to 409.65 sec, confidence is 57.57%\n",
            "crucial              from 416.97 sec to 417.90 sec, confidence is 82.20%\n",
            "golden               from 420.18 sec to 420.96 sec, confidence is 11.92%\n",
            "no                   from 424.77 sec to 425.64 sec, confidence is 68.79%\n",
            "core                 from 431.76 sec to 432.09 sec, confidence is 49.83%\n",
            "group                from 432.09 sec to 432.54 sec, confidence is 68.23%\n",
            "oh                   from 434.01 sec to 434.46 sec, confidence is 97.08%\n",
            "no                   from 434.46 sec to 434.79 sec, confidence is 97.08%\n",
            "she                  from 434.79 sec to 435.07 sec, confidence is 97.08%\n",
            "does                 from 435.07 sec to 435.69 sec, confidence is 78.15%\n",
            "just                 from 438.66 sec to 439.06 sec, confidence is 84.48%\n",
            "a                    from 439.38 sec to 439.62 sec, confidence is 52.43%\n",
            "question             from 439.65 sec to 440.28 sec, confidence is 75.01%\n",
            "of                   from 440.31 sec to 440.58 sec, confidence is 100.00%\n",
            "for                  from 444.30 sec to 444.63 sec, confidence is 30.26%\n",
            "the                  from 444.64 sec to 444.93 sec, confidence is 100.00%\n",
            "first                from 444.96 sec to 445.56 sec, confidence is 100.00%\n",
            "one                  from 445.56 sec to 446.07 sec, confidence is 78.91%\n",
            "was                  from 447.36 sec to 447.97 sec, confidence is 71.07%\n",
            "clean                from 447.97 sec to 448.50 sec, confidence is 41.50%\n",
            "warm                 from 448.50 sec to 449.46 sec, confidence is 82.24%\n",
            "he                   from 450.48 sec to 450.51 sec, confidence is 41.22%\n",
            "was                  from 451.62 sec to 452.37 sec, confidence is 99.23%\n",
            "cute                 from 452.37 sec to 452.79 sec, confidence is 81.96%\n",
            "two                  from 454.62 sec to 454.86 sec, confidence is 47.40%\n",
            "the                  from 460.08 sec to 460.80 sec, confidence is 100.00%\n",
            "current              from 460.83 sec to 461.52 sec, confidence is 86.97%\n",
            "an                   from 462.72 sec to 463.17 sec, confidence is 66.96%\n",
            "easy                 from 465.78 sec to 466.32 sec, confidence is 83.45%\n",
            "to                   from 467.16 sec to 467.49 sec, confidence is 100.00%\n",
            "remove               from 467.49 sec to 468.18 sec, confidence is 100.00%\n",
            "a                    from 469.74 sec to 469.98 sec, confidence is 43.01%\n",
            "king                 from 470.01 sec to 470.52 sec, confidence is 39.31%\n",
            "merck                from 474.81 sec to 475.56 sec, confidence is 29.28%\n",
            "there                from 479.40 sec to 479.91 sec, confidence is 30.59%\n",
            "sure                 from 479.93 sec to 480.84 sec, confidence is 70.80%\n",
            "white                from 481.95 sec to 482.43 sec, confidence is 53.06%\n",
            "british              from 482.43 sec to 483.27 sec, confidence is 73.01%\n",
            "shine                from 487.89 sec to 488.88 sec, confidence is 22.46%\n",
            "remote               from 497.58 sec to 498.33 sec, confidence is 54.31%\n",
            "no                   from 499.14 sec to 499.65 sec, confidence is 38.60%\n",
            "more                 from 499.65 sec to 500.40 sec, confidence is 42.58%\n",
            "then                 from 503.43 sec to 504.00 sec, confidence is 34.34%\n",
            "the                  from 504.40 sec to 504.57 sec, confidence is 67.42%\n",
            "reproduced           from 505.74 sec to 506.73 sec, confidence is 53.44%\n",
            "are                  from 507.36 sec to 507.66 sec, confidence is 100.00%\n",
            "you                  from 507.93 sec to 508.21 sec, confidence is 100.00%\n",
            "looking              from 508.21 sec to 508.83 sec, confidence is 76.69%\n",
            "for                  from 508.83 sec to 509.37 sec, confidence is 45.02%\n",
            "oh                   from 514.71 sec to 515.34 sec, confidence is 100.00%\n",
            "show                 from 515.52 sec to 516.39 sec, confidence is 100.00%\n",
            "on                   from 516.45 sec to 517.56 sec, confidence is 73.78%\n",
            "google               from 517.95 sec to 518.49 sec, confidence is 56.47%\n",
            "store                from 518.49 sec to 519.57 sec, confidence is 63.41%\n",
            "squirrel             from 519.91 sec to 520.50 sec, confidence is 71.90%\n",
            "to                   from 520.51 sec to 520.77 sec, confidence is 94.87%\n",
            "the                  from 520.77 sec to 521.43 sec, confidence is 99.82%\n",
            "two                  from 521.52 sec to 521.91 sec, confidence is 71.41%\n",
            "minutes              from 521.91 sec to 522.96 sec, confidence is 72.71%\n",
            "while                from 524.64 sec to 524.90 sec, confidence is 83.11%\n",
            "i'm                  from 524.90 sec to 525.21 sec, confidence is 46.65%\n",
            "still                from 525.22 sec to 525.81 sec, confidence is 74.16%\n",
            "that                 from 542.16 sec to 542.46 sec, confidence is 83.06%\n",
            "shy                  from 542.46 sec to 543.09 sec, confidence is 79.83%\n",
            "cap                  from 544.14 sec to 544.62 sec, confidence is 51.25%\n",
            "on                   from 544.62 sec to 544.83 sec, confidence is 44.07%\n",
            "him                  from 544.92 sec to 545.73 sec, confidence is 42.34%\n",
            "hey                  from 550.95 sec to 551.46 sec, confidence is 53.80%\n",
            "ashtray              from 552.63 sec to 553.26 sec, confidence is 44.92%\n",
            "sure                 from 560.85 sec to 561.36 sec, confidence is 23.01%\n",
            "yeah                 from 561.99 sec to 562.32 sec, confidence is 56.49%\n",
            "share                from 567.54 sec to 568.44 sec, confidence is 70.35%\n",
            "cashman              from 573.27 sec to 574.23 sec, confidence is 90.64%\n",
            "stream               from 583.86 sec to 585.06 sec, confidence is 15.13%\n",
            "the                  from 595.62 sec to 595.80 sec, confidence is 28.52%\n",
            "house                from 595.80 sec to 596.61 sec, confidence is 38.23%\n",
            "why                  from 597.84 sec to 598.38 sec, confidence is 45.20%\n",
            "more                 from 612.13 sec to 612.61 sec, confidence is 89.06%\n",
            "what                 from 613.75 sec to 614.38 sec, confidence is 68.91%\n",
            "are                  from 614.38 sec to 614.93 sec, confidence is 74.49%\n",
            "machina              from 614.93 sec to 615.94 sec, confidence is 41.15%\n",
            "oh                   from 643.78 sec to 644.32 sec, confidence is 49.21%\n",
            "she                  from 652.57 sec to 652.96 sec, confidence is 41.25%\n",
            "wrote                from 654.52 sec to 655.69 sec, confidence is 41.25%\n",
            "hirsh                from 661.75 sec to 664.75 sec, confidence is 100.00%\n",
            "robinson             from 665.38 sec to 666.07 sec, confidence is 100.00%\n",
            "or                   from 666.07 sec to 666.16 sec, confidence is 57.84%\n",
            "work                 from 666.16 sec to 666.55 sec, confidence is 94.93%\n",
            "washable             from 666.55 sec to 667.36 sec, confidence is 96.98%\n",
            "garage               from 668.47 sec to 668.92 sec, confidence is 39.54%\n",
            "worker               from 668.92 sec to 669.79 sec, confidence is 39.54%\n",
            "all                  from 672.10 sec to 672.82 sec, confidence is 45.66%\n",
            "searched             from 674.26 sec to 675.10 sec, confidence is 71.48%\n",
            "we're                from 679.87 sec to 680.26 sec, confidence is 70.39%\n",
            "sinbad               from 680.32 sec to 681.03 sec, confidence is 23.63%\n",
            "bread                from 681.03 sec to 681.28 sec, confidence is 30.35%\n",
            "me                   from 684.25 sec to 684.82 sec, confidence is 81.73%\n",
            "too                  from 686.59 sec to 686.92 sec, confidence is 53.51%\n",
            "was                  from 687.43 sec to 688.09 sec, confidence is 75.57%\n",
            "that                 from 689.23 sec to 689.41 sec, confidence is 75.57%\n",
            "a                    from 689.41 sec to 689.55 sec, confidence is 75.57%\n",
            "virtue               from 689.92 sec to 690.61 sec, confidence is 38.56%\n",
            "one                  from 696.31 sec to 697.13 sec, confidence is 38.10%\n",
            "for                  from 708.09 sec to 708.52 sec, confidence is 77.58%\n",
            "the                  from 708.55 sec to 708.73 sec, confidence is 93.31%\n",
            "circle               from 708.73 sec to 709.54 sec, confidence is 100.00%\n",
            "arab                 from 709.60 sec to 710.26 sec, confidence is 48.63%\n",
            "spring               from 710.56 sec to 711.31 sec, confidence is 48.63%\n",
            "there                from 712.39 sec to 713.17 sec, confidence is 75.64%\n",
            "i                    from 714.34 sec to 714.58 sec, confidence is 73.50%\n",
            "wanna                from 714.58 sec to 715.12 sec, confidence is 57.46%\n",
            "check                from 715.21 sec to 715.66 sec, confidence is 96.76%\n",
            "for                  from 715.66 sec to 715.96 sec, confidence is 96.76%\n",
            "memory               from 716.08 sec to 717.01 sec, confidence is 98.54%\n",
            "he                   from 718.15 sec to 718.45 sec, confidence is 64.87%\n",
            "has                  from 718.69 sec to 719.50 sec, confidence is 76.21%\n",
            "first                from 721.36 sec to 721.78 sec, confidence is 22.87%\n"
          ]
        }
      ],
      "source": [
        "import wave\n",
        "import json\n",
        "\n",
        "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
        "import Word as custom_Word\n",
        "\n",
        "model_path = \"models/vosk-model-en-us-0.21\"\n",
        "audio_filename = \"./adrd-data/Group2/eyetrack_video_pc0005.wav\"\n",
        "\n",
        "model = Model(model_path)\n",
        "wf = wave.open(audio_filename, \"rb\")\n",
        "rec = KaldiRecognizer(model, wf.getframerate())\n",
        "rec.SetWords(True)\n",
        "\n",
        "# get the list of JSON dictionaries\n",
        "results = []\n",
        "# recognize speech using vosk model\n",
        "while True:\n",
        "    data = wf.readframes(4000)\n",
        "    if len(data) == 0:\n",
        "        break\n",
        "    if rec.AcceptWaveform(data):\n",
        "        part_result = json.loads(rec.Result())\n",
        "        results.append(part_result)\n",
        "part_result = json.loads(rec.FinalResult())\n",
        "results.append(part_result)\n",
        "\n",
        "# convert list of JSON dictionaries to list of 'Word' objects\n",
        "list_of_words = []\n",
        "for sentence in results:\n",
        "    if len(sentence) == 1:\n",
        "        # sometimes there are bugs in recognition\n",
        "        # and it returns an empty dictionary\n",
        "        # {'text': ''}\n",
        "        continue\n",
        "    for obj in sentence['result']:\n",
        "        w = Word(obj)  # create custom Word object\n",
        "        list_of_words.append(w)  # and add it to list\n",
        "\n",
        "wf.close()  # close audiofile\n",
        "\n",
        "# output to the screen\n",
        "for word in list_of_words:\n",
        "    print(word.to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afBXJtgl5bvi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-n5_E1u5b1n",
        "outputId": "2568daa8-49ba-4f08-93db-00890e9a9cb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading your vosk model 'models/vosk-model-en-us-0.21'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
            "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 1 orphan nodes.\n",
            "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 2 orphan components.\n",
            "LOG (VoskAPI:Collapse():nnet-utils.cc:1488) Added 1 components, removed 2\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from models/vosk-model-en-us-0.21/ivector/final.ie\n",
            "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
            "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from models/vosk-model-en-us-0.21/graph/HCLG.fst\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:294) Loading words from models/vosk-model-en-us-0.21/graph/words.txt\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo models/vosk-model-en-us-0.21/graph/phones/word_boundary.int\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading subtract G.fst model from models/vosk-model-en-us-0.21/rescore/G.fst\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:312) Loading CARPA model from models/vosk-model-en-us-0.21/rescore/G.carpa\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:318) Loading RNNLM model from models/vosk-model-en-us-0.21/rnnlm/final.raw\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'models/vosk-model-en-us-0.21' model was successfully read\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import wave\n",
        "import json\n",
        "\n",
        "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
        "# !pip install vosk\n",
        "import Word\n",
        "\n",
        "SetLogLevel(0)\n",
        "\n",
        " # path to vosk model downloaded from\n",
        "# https://alphacephei.com/vosk/models\n",
        "model_path = \"models/vosk-model-en-us-0.21\"\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Please download the model from https://alphacephei.com/vosk/models and unpack as {model_path}\")\n",
        "    #sys.exit()\n",
        "\n",
        "print(f\"Reading your vosk model '{model_path}'...\")\n",
        "model = Model(model_path)\n",
        "print(f\"'{model_path}' model was successfully read\")\n",
        "\n",
        "# name of the audio file to recognize\n",
        "audio_filename = \"./adrd-data/Group2/eyetrack_video_pc0005.wav\"\n",
        "\n",
        "# name of the text file to write recognized text\n",
        "text_filename = \"speech_recognition_systems_vosk_with_timestamps.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkt00n4K3_mr",
        "outputId": "d67eab1a-7ad1-4a58-bd4a-07ff239b1398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading your file './adrd-data/Group2/eyetrack_video_pc0005.wav'...\n",
            "'./adrd-data/Group2/eyetrack_video_pc0005.wav' file was successfully read\n",
            "Audio file must be WAV format mono PCM.\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if not os.path.exists(audio_filename):\n",
        "    print(f\"File '{audio_filename}' doesn't exist\")\n",
        "    sys.exit()\n",
        "\n",
        "print(f\"Reading your file '{audio_filename}'...\")\n",
        "wf = wave.open(audio_filename, \"rb\")\n",
        "print(f\"'{audio_filename}' file was successfully read\")\n",
        "\n",
        "# check if audio is mono wav\n",
        "if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
        "    print(\"Audio file must be WAV format mono PCM.\")\n",
        "    sys.exit()\n",
        "\n",
        "rec = KaldiRecognizer(model, wf.getframerate())\n",
        "rec.SetWords(True)\n",
        "\n",
        "results = []\n",
        "\n",
        "# recognize speech using vosk model\n",
        "while True:\n",
        "    data = wf.readframes(4000)\n",
        "    if len(data) == 0:\n",
        "        break\n",
        "    if rec.AcceptWaveform(data):\n",
        "        part_result = json.loads(rec.Result())\n",
        "        results.append(part_result)\n",
        "\n",
        "part_result = json.loads(rec.FinalResult())\n",
        "results.append(part_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXC9rA2l0fpi",
        "outputId": "6be1dfdf-51b9-436b-a526-02e515a3d199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'result': [{'conf': 1.0, 'end': 3.39, 'start': 3.24, 'word': 'a'},\n",
              "   {'conf': 1.0, 'end': 3.81, 'start': 3.39, 'word': 'woman'},\n",
              "   {'conf': 1.0, 'end': 4.17, 'start': 3.81, 'word': 'is'},\n",
              "   {'conf': 0.836633, 'end': 4.68, 'start': 4.17, 'word': 'drying'},\n",
              "   {'conf': 1.0, 'end': 4.8, 'start': 4.68, 'word': 'a'},\n",
              "   {'conf': 1.0, 'end': 5.19, 'start': 4.8, 'word': 'dish'},\n",
              "   {'conf': 1.0, 'end': 5.52, 'start': 5.22, 'word': 'as'},\n",
              "   {'conf': 1.0, 'end': 6.12, 'start': 5.52, 'word': 'she'},\n",
              "   {'conf': 1.0, 'end': 7.53, 'start': 6.72, 'word': 'stands'},\n",
              "   {'conf': 1.0, 'end': 7.68, 'start': 7.53, 'word': 'by'},\n",
              "   {'conf': 1.0, 'end': 7.8, 'start': 7.68, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 8.16, 'start': 7.8, 'word': 'kitchen'},\n",
              "   {'conf': 1.0, 'end': 8.58, 'start': 8.16, 'word': 'sink'},\n",
              "   {'conf': 1.0, 'end': 8.73, 'start': 8.61, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 9.12, 'start': 8.73, 'word': 'kitchen'},\n",
              "   {'conf': 1.0, 'end': 9.45, 'start': 9.12, 'word': 'sink'},\n",
              "   {'conf': 1.0, 'end': 9.72, 'start': 9.48, 'word': 'is'},\n",
              "   {'conf': 1.0, 'end': 10.5, 'start': 9.72, 'word': 'overflowing'},\n",
              "   {'conf': 1.0, 'end': 10.71, 'start': 10.5, 'word': 'with'},\n",
              "   {'conf': 1.0, 'end': 10.8, 'start': 10.71, 'word': 'a'},\n",
              "   {'conf': 1.0, 'end': 11.07, 'start': 10.8, 'word': 'lot'},\n",
              "   {'conf': 1.0, 'end': 11.22, 'start': 11.07, 'word': 'of'},\n",
              "   {'conf': 1.0, 'end': 11.64, 'start': 11.22, 'word': 'water'},\n",
              "   {'conf': 1.0, 'end': 12.03, 'start': 11.64, 'word': 'onto'},\n",
              "   {'conf': 1.0, 'end': 12.15, 'start': 12.03, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 12.75, 'start': 12.15, 'word': 'ground'},\n",
              "   {'conf': 1.0, 'end': 13.17, 'start': 12.96, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 13.53, 'start': 13.17, 'word': 'woman'},\n",
              "   {'conf': 1.0, 'end': 13.68, 'start': 13.53, 'word': 'is'},\n",
              "   {'conf': 1.0, 'end': 13.92, 'start': 13.68, 'word': 'also'},\n",
              "   {'conf': 1.0, 'end': 14.37, 'start': 13.92, 'word': 'stepping'},\n",
              "   {'conf': 1.0, 'end': 14.61, 'start': 14.37, 'word': 'into'},\n",
              "   {'conf': 1.0, 'end': 14.73, 'start': 14.61, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 15.09, 'start': 14.73, 'word': 'puddle'},\n",
              "   {'conf': 1.0, 'end': 15.21, 'start': 15.09, 'word': 'of'},\n",
              "   {'conf': 1.0, 'end': 15.75, 'start': 15.21, 'word': 'water'},\n",
              "   {'conf': 1.0, 'end': 16.29, 'start': 16.14, 'word': 'the'},\n",
              "   {'conf': 0.336996, 'end': 16.65, 'start': 16.29, 'word': \"woman's\"},\n",
              "   {'conf': 0.846831, 'end': 16.83, 'start': 16.65, 'word': 'look'},\n",
              "   {'conf': 1.0, 'end': 17.01, 'start': 16.83, 'word': 'out'},\n",
              "   {'conf': 1.0, 'end': 17.1, 'start': 17.01, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 17.88, 'start': 17.1, 'word': 'window'},\n",
              "   {'conf': 1.0, 'end': 18.87, 'start': 18.57, 'word': 'where'},\n",
              "   {'conf': 1.0, 'end': 18.99, 'start': 18.87, 'word': 'you'},\n",
              "   {'conf': 1.0, 'end': 19.17, 'start': 18.99, 'word': 'can'},\n",
              "   {'conf': 1.0, 'end': 19.35, 'start': 19.17, 'word': 'see'},\n",
              "   {'conf': 1.0, 'end': 19.44, 'start': 19.35, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 19.86, 'start': 19.44, 'word': 'houses'},\n",
              "   {'conf': 1.0, 'end': 20.1, 'start': 19.86, 'word': 'by'},\n",
              "   {'conf': 1.0, 'end': 20.4, 'start': 20.13, 'word': 'car'}],\n",
              "  'text': \"a woman is drying a dish as she stands by the kitchen sink the kitchen sink is overflowing with a lot of water onto the ground the woman is also stepping into the puddle of water the woman's look out the window where you can see the houses by car\"},\n",
              " {'result': [{'conf': 0.546382, 'end': 20.97, 'start': 20.43, 'word': 'then'},\n",
              "   {'conf': 1.0, 'end': 22.11, 'start': 21.72, 'word': 'and'},\n",
              "   {'conf': 1.0, 'end': 22.26, 'start': 22.11, 'word': 'to'},\n",
              "   {'conf': 1.0, 'end': 22.35, 'start': 22.26, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 22.74, 'start': 22.35, 'word': 'left'},\n",
              "   {'conf': 1.0, 'end': 22.8, 'start': 22.74, 'word': 'of'},\n",
              "   {'conf': 1.0, 'end': 22.92, 'start': 22.8, 'word': 'the'},\n",
              "   {'conf': 0.79516, 'end': 23.28867, 'start': 22.92, 'word': 'woman'},\n",
              "   {'conf': 0.479065, 'end': 23.52, 'start': 23.343799, 'word': 'or'},\n",
              "   {'conf': 0.90775, 'end': 23.82, 'start': 23.530543, 'word': 'two'},\n",
              "   {'conf': 1.0, 'end': 24.51, 'start': 23.82, 'word': 'children'},\n",
              "   {'conf': 1.0, 'end': 25.11, 'start': 24.93, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 25.44, 'start': 25.11, 'word': 'little'},\n",
              "   {'conf': 1.0, 'end': 25.8, 'start': 25.47, 'word': 'girl'},\n",
              "   {'conf': 1.0, 'end': 25.95, 'start': 25.8, 'word': 'is'},\n",
              "   {'conf': 1.0, 'end': 26.34, 'start': 25.95, 'word': 'laughing'},\n",
              "   {'conf': 1.0, 'end': 26.43, 'start': 26.34, 'word': 'at'},\n",
              "   {'conf': 1.0, 'end': 26.52, 'start': 26.43, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 26.82, 'start': 26.52, 'word': 'little'},\n",
              "   {'conf': 1.0, 'end': 27.36, 'start': 26.82, 'word': 'boy'},\n",
              "   {'conf': 1.0, 'end': 27.81, 'start': 27.6, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 28.23, 'start': 27.81, 'word': 'boy'},\n",
              "   {'conf': 1.0, 'end': 28.53, 'start': 28.26, 'word': 'seems'},\n",
              "   {'conf': 1.0, 'end': 28.59, 'start': 28.53, 'word': 'to'},\n",
              "   {'conf': 1.0, 'end': 28.68, 'start': 28.59, 'word': 'be'},\n",
              "   {'conf': 1.0, 'end': 29.1, 'start': 28.68, 'word': 'falling'},\n",
              "   {'conf': 1.0, 'end': 29.4, 'start': 29.13, 'word': 'off'},\n",
              "   {'conf': 1.0, 'end': 29.46, 'start': 29.4, 'word': 'a'},\n",
              "   {'conf': 1.0, 'end': 29.91, 'start': 29.46, 'word': 'stool'},\n",
              "   {'conf': 1.0, 'end': 30.18, 'start': 29.94, 'word': 'as'},\n",
              "   {'conf': 1.0, 'end': 30.3, 'start': 30.18, 'word': 'he'},\n",
              "   {'conf': 1.0, 'end': 30.66, 'start': 30.3, 'word': 'reaches'},\n",
              "   {'conf': 1.0, 'end': 30.81, 'start': 30.66, 'word': 'for'},\n",
              "   {'conf': 1.0, 'end': 30.87, 'start': 30.81, 'word': 'a'},\n",
              "   {'conf': 1.0, 'end': 31.14, 'start': 30.87, 'word': 'jar'},\n",
              "   {'conf': 1.0, 'end': 31.2, 'start': 31.14, 'word': 'of'},\n",
              "   {'conf': 1.0, 'end': 31.86, 'start': 31.23, 'word': 'cookies'},\n",
              "   {'conf': 1.0, 'end': 32.34, 'start': 32.19, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 32.7, 'start': 32.34, 'word': 'girl'},\n",
              "   {'conf': 1.0, 'end': 32.88, 'start': 32.7, 'word': 'is'},\n",
              "   {'conf': 1.0, 'end': 33.03, 'start': 32.88, 'word': 'on'},\n",
              "   {'conf': 1.0, 'end': 33.12, 'start': 33.03, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 33.45, 'start': 33.12, 'word': 'floor'},\n",
              "   {'conf': 1.0, 'end': 33.6, 'start': 33.45, 'word': 'and'},\n",
              "   {'conf': 0.663291, 'end': 33.72, 'start': 33.6, 'word': 'she'},\n",
              "   {'conf': 0.663291, 'end': 33.84, 'start': 33.72, 'word': 'is'},\n",
              "   {'conf': 1.0, 'end': 34.17, 'start': 33.84, 'word': 'laughing'},\n",
              "   {'conf': 1.0, 'end': 34.26, 'start': 34.17, 'word': 'at'},\n",
              "   {'conf': 1.0, 'end': 34.35, 'start': 34.26, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 34.92, 'start': 34.35, 'word': 'guy'},\n",
              "   {'conf': 1.0, 'end': 36.39, 'start': 35.91, 'word': 'and'},\n",
              "   {'conf': 1.0, 'end': 36.57, 'start': 36.39, 'word': 'the'},\n",
              "   {'conf': 0.688451, 'end': 36.99, 'start': 36.57, 'word': \"woman's\"},\n",
              "   {'conf': 0.793515, 'end': 37.41, 'start': 36.99, 'word': 'usually'},\n",
              "   {'conf': 0.845364, 'end': 38.01, 'start': 37.41, 'word': 'unbothered'},\n",
              "   {'conf': 1.0, 'end': 38.13, 'start': 38.01, 'word': 'by'},\n",
              "   {'conf': 1.0, 'end': 38.25, 'start': 38.13, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 38.64, 'start': 38.25, 'word': 'fact'},\n",
              "   {'conf': 1.0, 'end': 38.94, 'start': 38.64, 'word': 'that'},\n",
              "   {'conf': 1.0, 'end': 39.33, 'start': 39.15, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 39.63, 'start': 39.33, 'word': 'little'},\n",
              "   {'conf': 0.401565, 'end': 39.99, 'start': 39.63, 'word': 'boys'},\n",
              "   {'conf': 1.0, 'end': 40.32, 'start': 39.99, 'word': 'falling'},\n",
              "   {'conf': 1.0, 'end': 40.56, 'start': 40.32, 'word': 'off'}],\n",
              "  'text': \"then and to the left of the woman or two children the little girl is laughing at the little boy the boy seems to be falling off a stool as he reaches for a jar of cookies the girl is on the floor and she is laughing at the guy and the woman's usually unbothered by the fact that the little boys falling off\"},\n",
              " {'result': [{'conf': 0.623446, 'end': 40.65, 'start': 40.56, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 41.28, 'start': 40.65, 'word': 'stool'},\n",
              "   {'conf': 1.0, 'end': 41.73, 'start': 41.43, 'word': 'she'},\n",
              "   {'conf': 1.0, 'end': 41.88, 'start': 41.73, 'word': 'is'},\n",
              "   {'conf': 1.0, 'end': 42.12, 'start': 41.88, 'word': 'just'},\n",
              "   {'conf': 1.0, 'end': 42.3, 'start': 42.12, 'word': 'look'},\n",
              "   {'conf': 1.0, 'end': 42.45, 'start': 42.3, 'word': 'out'},\n",
              "   {'conf': 1.0, 'end': 42.57, 'start': 42.45, 'word': 'the'},\n",
              "   {'conf': 1.0, 'end': 43.11, 'start': 42.57, 'word': 'window'}],\n",
              "  'text': 'the stool she is just look out the window'}]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaxkeQ3645y_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JsevTirH6eeB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading your vosk model 'models/vosk-model-en-us-0.21'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
            "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 1 orphan nodes.\n",
            "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 2 orphan components.\n",
            "LOG (VoskAPI:Collapse():nnet-utils.cc:1488) Added 1 components, removed 2\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from models/vosk-model-en-us-0.21/ivector/final.ie\n",
            "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
            "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from models/vosk-model-en-us-0.21/graph/HCLG.fst\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:294) Loading words from models/vosk-model-en-us-0.21/graph/words.txt\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:303) Loading winfo models/vosk-model-en-us-0.21/graph/phones/word_boundary.int\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:310) Loading subtract G.fst model from models/vosk-model-en-us-0.21/rescore/G.fst\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:312) Loading CARPA model from models/vosk-model-en-us-0.21/rescore/G.carpa\n",
            "LOG (VoskAPI:ReadDataFiles():model.cc:318) Loading RNNLM model from models/vosk-model-en-us-0.21/rnnlm/final.raw\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'models/vosk-model-en-us-0.21' model was successfully read\n",
            "Reading your file './later_data/pd0002_audio_final.wav'...\n",
            "'./later_data/pd0002_audio_final.wav' file was successfully read\n"
          ]
        }
      ],
      "source": [
        "######. This code works and generates word and starting and end point  ## requires human validation\n",
        "######\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import wave\n",
        "import json\n",
        "import yaml\n",
        "\n",
        "from vosk import Model, KaldiRecognizer, SetLogLevel\n",
        "# !pip install vosk\n",
        "import Word\n",
        "\n",
        "SetLogLevel(0)\n",
        "\n",
        " # path to vosk model downloaded from\n",
        "# https://alphacephei.com/vosk/models\n",
        "model_path = \"models/vosk-model-en-us-0.21\"\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Please download the model from https://alphacephei.com/vosk/models and unpack as {model_path}\")\n",
        "    #sys.exit()\n",
        "\n",
        "print(f\"Reading your vosk model '{model_path}'...\")\n",
        "model = Model(model_path)\n",
        "print(f\"'{model_path}' model was successfully read\")\n",
        "\n",
        "# name of the audio file to recognize\n",
        "audio_filename = \"./later_data/pd0002_audio_final.wav\"\n",
        "\n",
        "# name of the text file to write recognized text\n",
        "text_filename = \"speech_recognition_systems_vosk_with_timestamps.txt\"\n",
        "\n",
        "\n",
        "import os\n",
        "if not os.path.exists(audio_filename):\n",
        "    print(f\"File '{audio_filename}' doesn't exist\")\n",
        "    sys.exit()\n",
        "\n",
        "print(f\"Reading your file '{audio_filename}'...\")\n",
        "wf = wave.open(audio_filename, \"rb\")\n",
        "print(f\"'{audio_filename}' file was successfully read\")\n",
        "\n",
        "#check if audio is mono wav\n",
        "if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getcomptype() != \"NONE\":\n",
        "    print(\"Audio file must be WAV format mono PCM.\")\n",
        "    sys.exit()\n",
        "\n",
        "rec = KaldiRecognizer(model, wf.getframerate())\n",
        "rec.SetWords(True)\n",
        "\n",
        "results = []\n",
        "\n",
        "# recognize speech using vosk model\n",
        "while True: \n",
        "    data = wf.readframes(4000)\n",
        "    if len(data) == 0:\n",
        "        break\n",
        "    if rec.AcceptWaveform(data):\n",
        "        part_result = json.loads(rec.Result())\n",
        "        results.append(part_result)\n",
        "\n",
        "part_result = json.loads(rec.FinalResult())\n",
        "results.append(part_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-esPYpkc6uow",
        "outputId": "4bbc082d-027e-40eb-aebf-3bfbdf68624d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to './later_data/pd0002_transcript.yaml'\n"
          ]
        }
      ],
      "source": [
        "yaml_filename = \"./later_data/pd0002_transcript.yaml\"\n",
        "with open(yaml_filename, \"w\") as yaml_file:\n",
        "    yaml.dump(results, yaml_file, default_flow_style=False)\n",
        "\n",
        "print(f\"Results saved to '{yaml_filename}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZos8U6k78k9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mt4u2xee78n-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX9FjIgb78rQ"
      },
      "outputs": [],
      "source": [
        "#### Look for Image\n",
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Load the image\n",
        "image_path = \"/content/cookie_theft_outline.png\"\n",
        "\n",
        "image = Image.open(image_path)\n",
        "\n",
        "\n",
        "# Reshape the image to a 2D array of pixels\n",
        "pixels = np.array(image)\n",
        "#print(pixels.shape)\n",
        "#print(pixels[200][10:200])\n",
        "\n",
        "#pixels = pixels.reshape((-1, 3))\n",
        "#print(pixels.shape)\n",
        "#display(image)\n",
        "\n",
        "list_of_arrays = []\n",
        "for y in range(0, 943):\n",
        "  for x in range(0, 1302):\n",
        "\n",
        "    # Check if the new array doesn't exist in list_of_arrays\n",
        "    fourelementarray = pixels[y][x]\n",
        "    #print(fourelementarray.shape)\n",
        "    fourelementarray = pixels[y][x]\n",
        "    print(fourelementarray)\n",
        "    list_of_arrays.append(fourelementarray)\n",
        "    print(list_of_arrays)\n",
        "    if all((fourelementarray != existing_array).all() for existing_array in list_of_arrays):\n",
        "        list_of_arrays.append(fourelementarray)\n",
        "        print(\"New array added:\", fourelementarray)\n",
        "\n",
        "print(\"Updated list of arrays:\", list_of_arrays)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blubv_5vCJxw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D29ZZNeiAHFB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Convert pixel values to floating point\n",
        "pixels = np.float32(pixels)\n",
        "\n",
        "# Set the number of clusters (unique colors) you want to detect\n",
        "num_clusters = 12\n",
        "\n",
        "# Perform K-means clustering\n",
        "kmeans = KMeans(n_clusters=num_clusters)\n",
        "kmeans.fit(pixels)\n",
        "\n",
        "# Get the cluster centers (unique colors)\n",
        "unique_colors = kmeans.cluster_centers_\n",
        "\n",
        "# Convert unique colors to integer values\n",
        "unique_colors = np.uint8(unique_colors)\n",
        "\n",
        "# Create a blank canvas to display the unique colors\n",
        "canvas_width = 100 * num_clusters\n",
        "canvas = Image.new(\"RGB\", (canvas_width, 100), \"black\")\n",
        "draw = ImageDraw.Draw(canvas)\n",
        "\n",
        "# Draw rectangles for each unique color\n",
        "for i, color in enumerate(unique_colors):\n",
        "    x_start = i * 100\n",
        "    x_end = x_start + 100\n",
        "    draw.rectangle([(x_start, 0), (x_end, 100)], fill=tuple(color.tolist()))\n",
        "\n",
        "# Display the canvas with unique colors\n",
        "#canvas.show()\n",
        "display(canvas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ee7YpnNF8chT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
